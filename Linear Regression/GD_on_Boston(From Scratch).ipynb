{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33134a63",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6df1507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01f13d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.407850</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.266023</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.576134</td>\n",
       "      <td>1.239974</td>\n",
       "      <td>0.840122</td>\n",
       "      <td>-0.520264</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.278354</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.410571</td>\n",
       "      <td>-1.097990</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.407374</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.247057</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-1.016689</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>-0.838337</td>\n",
       "      <td>0.336351</td>\n",
       "      <td>-0.523001</td>\n",
       "      <td>-0.060801</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.291169</td>\n",
       "      <td>-0.520474</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125179</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>1.015999</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>1.367490</td>\n",
       "      <td>-0.439699</td>\n",
       "      <td>0.687212</td>\n",
       "      <td>-0.577309</td>\n",
       "      <td>1.661245</td>\n",
       "      <td>1.530926</td>\n",
       "      <td>0.806576</td>\n",
       "      <td>-3.795795</td>\n",
       "      <td>0.891076</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028304</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>1.015999</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>1.859875</td>\n",
       "      <td>-0.047918</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>-0.712836</td>\n",
       "      <td>1.661245</td>\n",
       "      <td>1.530926</td>\n",
       "      <td>0.806576</td>\n",
       "      <td>-0.066050</td>\n",
       "      <td>0.215438</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412408</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.969827</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.913029</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>-0.834781</td>\n",
       "      <td>0.300508</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-0.957633</td>\n",
       "      <td>0.020560</td>\n",
       "      <td>0.431074</td>\n",
       "      <td>0.029007</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     # CRIM        ZN     INDUS      CHAS       NOX        RM       AGE   \n",
       "0 -0.407850 -0.487722 -1.266023 -0.272599 -0.576134  1.239974  0.840122  \\\n",
       "1 -0.407374 -0.487722  0.247057 -0.272599 -1.016689  0.001946 -0.838337   \n",
       "2  0.125179 -0.487722  1.015999 -0.272599  1.367490 -0.439699  0.687212   \n",
       "3  0.028304 -0.487722  1.015999 -0.272599  1.859875 -0.047918  0.801005   \n",
       "4 -0.412408 -0.487722 -0.969827 -0.272599 -0.913029 -0.384137 -0.834781   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT     Y  \n",
       "0 -0.520264 -0.752922 -1.278354 -0.303094  0.410571 -1.097990  37.9  \n",
       "1  0.336351 -0.523001 -0.060801  0.113032  0.291169 -0.520474  21.4  \n",
       "2 -0.577309  1.661245  1.530926  0.806576 -3.795795  0.891076  12.7  \n",
       "3 -0.712836  1.661245  1.530926  0.806576 -0.066050  0.215438  19.9  \n",
       "4  0.300508 -0.752922 -0.957633  0.020560  0.431074  0.029007  22.5  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Boston dataset from CSV file and displaying frist 5 rows\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "# X_train = df.drop(df[\"Y\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8091433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns by removing leading '#' and stripping spaces\n",
    "df.columns = df.columns.str.replace('#', '').str.strip()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aebce71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((379, 13), (379,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Y', axis=1)\n",
    "y = df[\"Y\"]\n",
    "X.shape, y.shape \n",
    "# X_train.iloc[63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9ae9282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((265, 13), (114, 13))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58af8b",
   "metadata": {},
   "source": [
    "## Batch GDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0341887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Gradient Descent\n",
    "\n",
    "class GDRegressor:\n",
    "    \n",
    "    def __init__(self, lr = 0.01, epochs = 100):\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.m = None\n",
    "        self.c = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.c = 0\n",
    "        self.m = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            y_pred =  np.dot(X,self.m) + self.c\n",
    "            \n",
    "            der_m = (-2/X.shape[0]) * np.dot(X.T, (y - y_pred))\n",
    "            der_c = (-2) * np.mean(y - y_pred)\n",
    "            \n",
    "            self.m = self.m - self.lr * der_m\n",
    "            self.c = self.c - self.lr * der_c\n",
    "            \n",
    "        return self.m, self.c\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        return  np.dot(X,self.m) + self.c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a838af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = GDRegressor(lr = 0.01, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b3fe1ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.81611372,  0.09828713, -0.17254211,  0.66407146, -0.95043614,\n",
       "         3.10113171, -0.38087387, -1.80385045,  1.03814976, -0.2596327 ,\n",
       "        -1.82615967,  0.95820786, -3.96604492]),\n",
       " 22.2342996238665)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the GDRegressor model on the provided training data.\n",
    "\n",
    "gd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4b324615",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "33cd568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04a9ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 3.3043666972957553\n",
      "Mean Squared Error: 20.49611995993805\n",
      "R2 Score: 0.7583132203351639\n"
     ]
    }
   ],
   "source": [
    "# Calculating and displaying the performance metrics of the trained GDRegressor model.\n",
    "\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 Score:\",r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5b895",
   "metadata": {},
   "source": [
    "## Stochastic GDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c225c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "class SGDRegressor:\n",
    "    \n",
    "    def __init__(self, lr = 0.01, epochs = 100):\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.m = None\n",
    "        self.c = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.c = 0\n",
    "        self.m = np.ones(X.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            for j in range(X.shape[0]):\n",
    "                \n",
    "                ran_num = np.random.randint(0, X.shape[0])\n",
    "                y_hat = np.dot(X.iloc[ran_num], self.m) + self.c\n",
    "                \n",
    "                der_m = (-2) * np.dot((y.iloc[ran_num]-y_hat),X.iloc[ran_num])\n",
    "                der_c = (-2) * ((y.iloc[ran_num]-y_hat))\n",
    "                \n",
    "                self.m = self.m - self.lr * der_m\n",
    "                self.c = self.c - self.lr * der_c\n",
    "            \n",
    "        return self.m, self.c\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        return  np.dot(X,self.m) + self.c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6e20f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(lr = 0.01,epochs = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a788769a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.82405994,  0.92591311,  0.2827904 ,  0.77455624, -2.65308938,\n",
       "         2.35327388,  0.16945467, -3.15568233,  2.60092138, -1.1934712 ,\n",
       "        -2.5021802 , -0.78007377, -4.12346414]),\n",
       " 23.003217931629038)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5124594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sgd = sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "afdbebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 3.655195772525519\n",
      "Mean Squared Error: 20.879810344312393\n",
      "R2 Score: 0.7537888082235518\n"
     ]
    }
   ],
   "source": [
    "# Calculating and displaying the performance metrics of the trained SGDRegressor model.\n",
    "\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred_sgd))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred_sgd))\n",
    "print(\"R2 Score:\",r2_score(y_test, y_pred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26bab97",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "Convergence:\n",
    "\n",
    "SGD: Converged in 60 epochs.\n",
    "\n",
    "BGD: Converged in 200 epochs.\n",
    "\n",
    "Computational Efficiency:\n",
    "\n",
    "SGD: Faster training due to updating weights after each random data point.\n",
    "\n",
    "BGD: Slower training as it processes the entire dataset in each epoch.\n",
    "\n",
    "Coherence of Results:\n",
    "\n",
    "SGD: Can be more erratic due to noisy updates, but can escape local minima.\n",
    "\n",
    "BGD: Generally smoother convergence towards the optimal solution.\n",
    "\n",
    "Performance Metrics:\n",
    "\n",
    "Both models have similar Mean Squared Errors and R2 Scores, indicating comparable predictive capability.\n",
    "SGD has a slightly higher Mean Absolute Error, indicating slightly less accuracy compared to BGD.\n",
    "\n",
    "Trade-off:\n",
    "\n",
    "SGD: Faster convergence, suitable for larger datasets; more variance in updates.\n",
    "\n",
    "BGD: Slower convergence, better suited for smaller datasets; smoother updates.\n",
    "\n",
    "But We have remember that both methods have their strengths and weaknesses, making one more suitable than the other depending on factors like dataset size, convergence speed, and stability of updates. SGD is useful for large datasets where BGD might be computationally expensive, but BGD can provide more stable convergence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a17bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
