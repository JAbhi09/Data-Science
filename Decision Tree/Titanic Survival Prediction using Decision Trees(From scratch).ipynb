{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55400e45",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8cd4157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15fd132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Titanic training dataset into a DataFrame.\n",
    "\n",
    "data = pd.read_csv(\"titanic_train.csv\", delimiter=',', encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8d751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   \n",
       "0            1         0       3  \\\n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp   \n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1  \\\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the few records.  \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b5260f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56da0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the cols which are not required for further processing.\n",
    "\n",
    "col_to_drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "data_clean = data.drop(col_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4252b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the \"Sex\" and Embarked Cols.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "data_clean[\"Sex\"] = le.fit_transform(data_clean[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50040012",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean[\"Embarked\"] = le.fit_transform(data_clean[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1f9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the Nan value of \"Age\" col with the mean value of it.\n",
    "\n",
    "data_clean = data_clean.fillna(data_clean[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92137af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
       "       'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking whether there is a whitespace or not in the cols name.\n",
    "\n",
    "# data_clean.columns = data_clean.columns.str.strip()\n",
    "data_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6491ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 7) (891,)\n"
     ]
    }
   ],
   "source": [
    "X = data_clean.iloc[:,:-1]  # Feature Variable\n",
    "Y = data_clean.iloc[:,-1]   # Label Variable\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c07dc1",
   "metadata": {},
   "source": [
    "##### Function to compute the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101805b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(col):\n",
    "    \n",
    "    counts = np.unique(col, return_counts=True)  # returns--->(unique value in arr like-array(0,1), array(freq of 0, fre of 1))\n",
    "    N = float(col.shape[0])\n",
    "    \n",
    "    ent = 0.0\n",
    "    for ix in counts[1]:          # iterate over array(freq of 0, fre of 1) \n",
    "        p = ix/N\n",
    "        \n",
    "        ent += (-1*p*np.log2(p))\n",
    "        \n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472ba335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function splits the input DataFrame into two subsets based on a specified feature (f_key) and threshold value (f_val).\n",
    "\n",
    "def divide_data(data, f_key, f_val):\n",
    "    x_right = pd.DataFrame(columns=data.columns)\n",
    "    x_left = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        \n",
    "        val = data.loc[i, f_key]   # Access a group of rows(i) and columns(f_key) by label(s) or a boolean array.\n",
    "     \n",
    "        if val > f_val:\n",
    "            x_right.loc[i] = data.loc[i]\n",
    "        \n",
    "        else:\n",
    "            x_left.loc[i] = data.loc[i]\n",
    "\n",
    "    return x_left, x_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc08aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example how it's gonna work\n",
    "\n",
    "x_left, x_right = divide_data(data_clean, \"Sex\", 0.5)\n",
    "# print(x_left)\n",
    "# print(x_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee015e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(data, f_key, f_value):\n",
    "    left, right = divide_data(data, f_key, f_value)\n",
    "    \n",
    "    # % of total samples are on left and right\n",
    "    l = float(left.shape[0])/data.shape[0]     # here left.shape[0] is 8 and left.shape[1] is 314 so instead of selecting \n",
    "    r = float(right.shape[0])/data.shape[0]  #left.shape[0] we have to select shape[1] or we can use x_left.transpose().shape[0]\n",
    "    \n",
    "#     print(left.shape[1])\n",
    "#     print(data.shape[1])\n",
    "    # if all sample come to one side i.e, ig is minimum \n",
    "    \n",
    "    if left.shape[0] == 0 or right.shape[0] == 0:\n",
    "        return -1000000000 # min information gain\n",
    "    \n",
    "    # Information gain formula is used here on survived col of dataset\n",
    "    \n",
    "    i_gain = entropy(data[\"Survived\"]) - (l*entropy(left[\"Survived\"]) + r*entropy(right[\"Survived\"]))\n",
    "  \n",
    "    return i_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad53bf87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for fx in X.columns:\n",
    "#     print(fx)\n",
    "#     print(information_gain(data_clean, fx, data_clean[fx].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91965f45",
   "metadata": {},
   "source": [
    "### Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f9e08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DesicionTree:\n",
    "    \n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, depth = 0, max_depth = 5):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.fkey = None\n",
    "        self.fval = None\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.target = None\n",
    "\n",
    "    def train(self, x_train):\n",
    "        \n",
    "        features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "        max_igain = []\n",
    "        \n",
    "        for ix in features:\n",
    "            i_gain = information_gain(x_train, ix, x_train[ix].mean())\n",
    "            max_igain.append(i_gain)\n",
    "            \n",
    "        self.fkey = features[np.argmax(max_igain)]\n",
    "        self.fval = x_train[self.fkey].mean()\n",
    "        print(\"Making Tree features is\", self.fkey)\n",
    "        \n",
    "        # Split Tree(Data)\n",
    "        data_left, data_right = divide_data(x_train, self.fkey, self.fval)\n",
    "        data_left = data_left.reset_index(drop = True)\n",
    "        data_right = data_right.reset_index(drop = True)\n",
    "        \n",
    "  # Way to terminate the tree\n",
    "\n",
    "        # Truly a leaf node by getting left or right node shape = 0\n",
    "        \n",
    "        if data_left.shape[0] == 0 or data_right.shape[0] == 0:\n",
    "            if x_train[\"Survived\"].mean() >= 0.5:\n",
    "                self.target = \"Survived\"\n",
    "            else:\n",
    "                self.target = \"Dead\"\n",
    "            return\n",
    "        \n",
    "        # Stop early when depth >= max_depth\n",
    "        if self.depth>=self.max_depth:\n",
    "            if x_train[\"Survived\"].mean() >= 0.5:\n",
    "                self.target = \"Survived\"\n",
    "            else:\n",
    "                self.target = \"Dead\"\n",
    "            return\n",
    "        \n",
    "        # When the base case is not hitting recursive case is used for making the left and right tree smaller sub-tree\n",
    "        \n",
    "        # Recursive Case\n",
    "        self.right = DesicionTree(depth = self.depth+1, max_depth=self.max_depth)\n",
    "        self.right.train(data_right)\n",
    "        \n",
    "        self.left = DesicionTree(depth = self.depth+1, max_depth = self.max_depth)\n",
    "        self.left.train(data_left)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # You can set the target at every node\n",
    "        if x_train[\"Survived\"].mean() >= 0.5:    \n",
    "            self.target = \"Survived\"\n",
    "        else:\n",
    "            self.target = \"Dead\"\n",
    "        return\n",
    "    \n",
    "    def predict(self,test):\n",
    "        \n",
    "        # go to right\n",
    "        if test[self.fkey]>self.fval:\n",
    "\n",
    "            if self.right is None:\n",
    "                return self.target\n",
    "            return self.right.predict(test)\n",
    "        \n",
    "        else:\n",
    "            if self.left is None:\n",
    "                return self.target\n",
    "            return self.left.predict(test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb10a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DesicionTree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be752e",
   "metadata": {},
   "source": [
    "# Train - Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa2d31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.7 * data_clean.shape[0])\n",
    "train_data = data_clean[:split]\n",
    "test_data = data_clean[split:]\n",
    "test_data = test_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c2b8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the DecisionTree class to train and build a decision tree for classification.\n",
    "dtree = DesicionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0023b3dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Tree features is Sex\n",
      "Making Tree features is Fare\n",
      "Making Tree features is Pclass\n",
      "Making Tree features is SibSp\n",
      "Making Tree features is Parch\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is SibSp\n",
      "Making Tree features is Parch\n",
      "Making Tree features is Embarked\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is Parch\n",
      "Making Tree features is Age\n",
      "Making Tree features is Embarked\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is Fare\n",
      "Making Tree features is SibSp\n",
      "Making Tree features is Pclass\n",
      "Making Tree features is Fare\n",
      "Making Tree features is Fare\n",
      "Making Tree features is Fare\n",
      "Making Tree features is SibSp\n",
      "Making Tree features is Age\n",
      "Making Tree features is Fare\n",
      "Making Tree features is Embarked\n",
      "Making Tree features is Pclass\n",
      "Making Tree features is Embarked\n",
      "Making Tree features is Fare\n",
      "Making Tree features is SibSp\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is Fare\n",
      "Making Tree features is SibSp\n",
      "Making Tree features is Age\n",
      "Making Tree features is Embarked\n",
      "Making Tree features is Parch\n",
      "Making Tree features is Pclass\n",
      "Making Tree features is SibSp\n",
      "Making Tree features is Fare\n",
      "Making Tree features is Fare\n",
      "Making Tree features is Fare\n",
      "Making Tree features is Embarked\n",
      "Making Tree features is Age\n",
      "Making Tree features is Pclass\n",
      "Making Tree features is Fare\n",
      "Making Tree features is Age\n",
      "Making Tree features is SibSp\n",
      "Making Tree features is SibSp\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n",
      "Making Tree features is SibSp\n",
      "Making Tree features is Age\n",
      "Making Tree features is Pclass\n",
      "Making Tree features is Age\n",
      "Making Tree features is Age\n"
     ]
    }
   ],
   "source": [
    "dtree.train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5d9e0",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "The output indicates the process of building the decision tree. The lines \"Making Tree features is...\" correspond to the key feature that the tree is using to split the data at each node. Based on the highest information gain, the decision tree chooses a feature to divide the data and build the tree structure recursively.\n",
    "\n",
    "In output, you can observe that the tree is selecting different features at different depths to create the splits. This process continues until either the tree reaches the specified maximum depth or a termination condition is met (such as all samples in a node belonging to the same class(other is zero) or when the depth limit is reached).\n",
    "\n",
    "So we can say that this decision tree seems to be effectively learning the important features and their corresponding thresholds to make classification decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc3f42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to predict the labels\n",
    "\n",
    "y_pred = []\n",
    "for i in range(test_data.shape[0]):\n",
    "    y_pred.append(dtree.predict(test_data.loc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "192ca27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = np.array(test_data[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "017642a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the predicted labels\n",
    "\n",
    "y_pred = le.fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba576e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8097014925373134\n"
     ]
    }
   ],
   "source": [
    "acc = np.sum(y_pred==y_actual)/y_pred.shape[0]\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b564d91a",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "Based on the results obtained from training and evaluating the Decision Tree classifier:\n",
    "\n",
    "The Decision Tree model achieved an accuracy of approximately 80.97% on the test dataset. This indicates that the model is able to predict the survival outcomes of passengers with a satisfactory level of accuracy. The model's performance suggests that it successfully learned important patterns and relationships within the training data, allowing it to generalize reasonably well to unseen data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
